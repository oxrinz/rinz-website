# Usability of LLMs in large scale projects
<br />
*Note: This article only talks about AI in programming related fields. Everything I say about AI might not be meant to be applied to other fields*
<br />
With tons of new AI coding tools coming out what feels like every new week, I rarely see anyone use them outside of "I made an Apple demo in 10 minutes" engagement bait twitter posts.
I am no expert, but from my observations, the main reasons look somewhat like this:
<br />
- Lack of consistency (or memory)
- Bad code quality
- Using LLMs is not "fun"
<br />
<br />
## Core problem
<br />
While code quality and consistency are aspects that may be improved through technological advancements in the coming years, the fundamental challenge of LLMs being cumbersome tools to work with remains a core issue. This problem is particularly evident in fields related to design and aesthetics, where many nuances are difficult to articulate verbally.
Consider, for instance, the visual appeal of a React component library. Its overall aesthetic is often a result of numerous subtle design choices and features that harmonize to create a distinct impression. Conveying this complex visual language to an LLM poses a significant challenge. How does one effectively communicate such nuanced design concepts using only text-based prompts?
<br />
Now yes, if you're lucky, the LLM of your choice might be educated on that particular library, and therefore you could imitate its style by communicating the library's name to the LLM.
This is however, a rare case.
If you aim for something unique, or simply lesser known, you're out of luck.
<br />
Keep in mind that this is assuming that lack of consistency and quality is solved, add those two on top of that, and you got a pretty faulty product.
<br />
<br />
## Current vision for the future of LLMs
<br />
There are many popular trends of thoughts that mainly consist of:
<br />
- No code development
- Auto-completing code
- Fully automated programming
<br />
Now those things are great, but realistically, I don't believe any of them (except the last one, in far, far future) will end up being how we use AI in programming.
<br />
Auto-completing is nice, yes, but from my experience, Copilot barely accelerated my speed of development. 
It also occasionally made mistakes, which slowed me down, although now by a considerable amount.
<br />
As for no code development, it sounds like a good idea. Until you realize that you can't make anything extensive without real programming knowledge.
In most cases, writing your own code rather than writing a prompt is easier, faster, and most importantly, more **fun**.
In large scale applications, it'd take you less time to write your own code than iterating prompts for an LLM that's prone to misinterpeting your use of language.
<br />
<br />
## The real solution
<br />
I think, as AI hype stabilizes, we'll find actual ways of using AI efficiently.
We'll slowly distance ourselves from using LLMs, and instead lean towards UIlike tools.
No code might even become a thing, but it definitely won't be prompting an LLM with text, but instead something else.
I think development will strive away from writing and working with code, and instead, the skill of software development will be confined to a new kind of development apps.
<br />
<br />
## Z-UI
<br />
Z-UI will be my attempt of innovating the way we use AI for programming.
It will be a manifestation of my vision of the future with AI. 
I have no money to run inference server, but honestly, I don't care. 
I'm going to do it anyway.
<br />
As for how exactly Z-UI is going to work, I don't know.
I'm yet to experiment for how to use AI with minimal amount of LLM prompting, this article only serves as a base for Z-UI.